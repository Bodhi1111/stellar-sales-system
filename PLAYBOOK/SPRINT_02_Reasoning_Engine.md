# Playbook: SPRINT 02 - Building The Reasoning Engine

## Sprint Goal

To re-architect the orchestrator into an advanced, agentic reasoning engine. By the end of this sprint, the system will be able to receive a user request, create a dynamic plan, execute it using specialist agents as "tools," and perform cognitive self-correction. This sprint adapts the core concepts (Gatekeeper, Planner, Auditor, Router) from the "Agentic RAG" article.

---

### Epic 2.1: Upgrading the Agent's Memory (The State)

**Objective:** To enhance the `AgentState` to support the new cognitive processes. The state needs to track not just the data, but the agent's *thought process*‚Äîits plan, its actions, its verifications, and its final conclusion.

#### **Task 2.1.1: Evolve the `AgentState`**

* **Rationale:** Our current state is a simple data container. The new state will be the central nervous system of our reasoning loop, tracking every step of the agent's "thinking" from the initial query to the final response. This is essential for the new cognitive nodes to function.
* **File to Modify:** `orchestrator/state.py`
* **Step 1: Add the Code**
    * The following complete code should replace the existing content of `orchestrator/state.py`.

    ```python
    from typing import TypedDict, List, Dict, Any, Optional
    from pathlib import Path

    class AgentState(TypedDict):
        """
        Represents the state of our agentic reasoning graph. It tracks not
        just data, but the agent's entire thought process.
        """
        # --- Inputs ---
        original_request: str # The initial user query for the Sales Copilot

        # --- Transcript Processing Data (from Sprint 1) ---
        file_path: Path
        raw_text: str
        structured_dialogue: List[Dict[str, Any]]
        chunks: List[str]
        transcript_id: Optional[int]
        extracted_entities: Dict[str, Any]

        # --- Agent's Cognitive Process ---
        plan: List[str] # The step-by-step plan generated by the Planner
        intermediate_steps: List[Dict[str, Any]] # A log of tool calls and their outputs
        verification_history: List[Dict[str, Any]] # A log of Auditor checks
        clarification_question: Optional[str] # If the Gatekeeper finds ambiguity

        # --- Final Output ---
        final_response: str # The synthesized final answer for the user

        # --- Legacy Fields for existing agents ---
        # We will phase these out as we upgrade the specialist agents
        email_draft: str
        social_content: Dict[str, Any]
        coaching_feedback: Dict[str, Any]
        crm_data: Dict[str, Any]
    ```

---

### Epic 2.2: Building the Cognitive Nodes

**Objective:** To create a new suite of agents whose sole purpose is to provide the "thinking" capabilities for our reasoning loop. These agents do not process the transcript directly; they process the *state* of the problem itself.

#### **Task 2.2.1: Create the `GatekeeperAgent`**

* **Rationale:** A common failure point for AI systems is ambiguous user queries. The Gatekeeper acts as a "guard rail," checking if a request is specific enough to be answered with high precision. If not, it asks for clarification, mimicking an expert human who asks clarifying questions before starting work.
* **Step 1: Create the Agent File**
    * Create a new directory and file: `agents/gatekeeper/gatekeeper_agent.py`.
* **Step 2: Add the Code**
    * The following complete code should be placed in `agents/gatekeeper/gatekeeper_agent.py`.

    ```python
    import json
    import requests
    from typing import Dict, Any

    from agents.base_agent import BaseAgent
    from config.settings import Settings

    class GatekeeperAgent(BaseAgent):
        """
        This agent acts as the first checkpoint. It checks if a user's request
        is specific enough to be answered, or if it's too ambiguous.
        """
        def __init__(self, settings: Settings):
            super().__init__(settings)
            self.api_url = settings.OLLAMA_API_URL
            self.model_name = settings.LLM_MODEL_NAME

        async def run(self, request: str) -> Dict[str, Any]:
            print("üßê GatekeeperAgent: Checking for ambiguity...")
            prompt = f"""
            You are an expert at identifying ambiguity in user requests for a sales analysis system.
            Given the user's request, is it specific enough to be answered with high precision using sales transcripts and financial data?

            - A specific request asks for a number, a date, a named risk, a client name, or a comparison (e.g., 'What was the main objection from Client X?', 'Show me email drafts for deals we won.').
            - An ambiguous request is open-ended (e.g., 'How are sales going?', 'What's the outlook?').

            If the request is ambiguous, formulate a single, polite question to the user that would provide the necessary clarification. Otherwise, respond with only the word "OK".

            User Request: "{request}"
            Response:
            """
            payload = {"model": self.model_name, "prompt": prompt, "stream": False}

            try:
                response = requests.post(self.api_url, json=payload).json().get("response", "").strip()
                if response == "OK":
                    print("   - Request is specific. Proceeding.")
                    return {"clarification_question": None}
                else:
                    print("   - Request is ambiguous. Generating clarification question.")
                    return {"clarification_question": response}
            except Exception as e:
                print(f"   ‚ùå ERROR in GatekeeperAgent: {e}")
                return {"clarification_question": "Error during ambiguity check."}
    ```

#### **Task 2.2.2: Create the `PlannerAgent`**

* **Rationale:** This agent is the strategic brain. It decomposes a user's request into a logical, step-by-step plan. Each step in the plan will be a call to one of our specialist agents (who will act as "tools"). This structured approach prevents the system from making a single, monolithic attempt to answer a complex question.
* **Step 1: Create the Agent File**
    * Create a new directory and file: `agents/planner/planner_agent.py`.
* **Step 2: Add the Code**
    * The following complete code should be placed in `agents/planner/planner_agent.py`.

    ```python
    import json
    import requests
    from typing import Dict, Any, List

    from agents.base_agent import BaseAgent
    from config.settings import Settings

    class PlannerAgent(BaseAgent):
        """
        This agent is the strategic brain. It creates a step-by-step plan
        to answer a user's request by selecting from available "tools"
        (our other specialist agents).
        """
        def __init__(self, settings: Settings):
            super().__init__(settings)
            self.api_url = settings.OLLAMA_API_URL
            self.model_name = settings.LLM_MODEL_NAME

        def _get_tool_descriptions(self) -> str:
            # In a real system, this could be dynamically generated.
            # For our playbook, we will hardcode the available tools.
            return """
            - sales_copilot_tool(query: str): Expert at retrieving information from the knowledge base (transcripts, emails, etc.). Use for questions about specific facts, summaries, or past events.
            - crm_tool(query: str): Expert at analyzing and summarizing data from the CRM. Use for questions about deal outcomes, client history, and sales performance metrics.
            - email_tool(query: str): Expert at drafting and analyzing sales emails. Use for requests to generate new emails or find examples of past emails.
            """

        async def run(self, request: str) -> Dict[str, Any]:
            print("üó∫Ô∏è PlannerAgent: Creating a plan...")
            tool_descriptions = self._get_tool_descriptions()
            prompt = f"""
            You are a master planner agent. Your task is to create a step-by-step plan to answer the user's request by intelligently selecting from the available tools.

            **Available Tools:**
            {tool_descriptions}

            **Instructions:**
            1. Analyze the user's request.
            2. Create a clear, step-by-step plan. Each step must be a call to one of the available tools. The input to the tool should be a concise query.
            3. The final step in your plan must ALWAYS be 'FINISH'.

            **Output Format:**
            Return the plan as a Python-parseable list of strings.
            For example: ["sales_copilot_tool('Find transcripts where the main objection was about price')", "email_tool('Draft a follow-up email for clients who objected to price')", "FINISH"]

            ---
            User Request: "{request}"
            Plan:
            """
            payload = {"model": self.model_name, "prompt": prompt, "stream": False}

            try:
                plan_str = requests.post(self.api_url, json=payload).json().get("response", "[]")
                # A simple but effective way to parse the LLM's list-like string output
                plan = eval(plan_str)
                print(f"   - Generated Plan: {plan}")
                return {"plan": plan}
            except Exception as e:
                print(f"   ‚ùå ERROR in PlannerAgent: {e}. Falling back to FINISH.")
                return {"plan": ["FINISH"]}
    ```

---
#### **Task 2.2.3: Create the `AuditorAgent` (for Self-Correction)**

* **Rationale:** A basic agent trusts its tools blindly. An advanced agent is a skeptic. The Auditor acts as a critical "second opinion." After a specialist agent (acting as a tool) runs, its output is passed to the Auditor to be validated against the original request. If the output is low-quality or irrelevant, this check allows our system to self-correct by looping back to the Planner to try a new approach.
* **Step 1: Create the Agent File**
    * Create a new directory and file: `agents/auditor/auditor_agent.py`.
* **Step 2: Define the Verification Structure (Pydantic)**
    * At the top of the new file, we will define a Pydantic model. This forces the Auditor LLM to return a structured, reliable score and reasoning, which is essential for our router's logic.

* **Step 3: Add the Code**
    * The following complete code should be placed in `agents/auditor/auditor_agent.py`.

    ```python
    import json
    import requests
    from typing import Dict, Any
    from pydantic import BaseModel, Field

    from agents.base_agent import BaseAgent
    from config.settings import Settings

    class VerificationResult(BaseModel):
        """Structured output for the Auditor node's verification."""
        confidence_score: int = Field(description="Score from 1-5 on confidence in the tool's output being relevant and correct.", ge=1, le=5)
        reasoning: str = Field(description="Brief reasoning for the confidence score.")

    class AuditorAgent(BaseAgent):
        """
        This agent acts as a critical "second opinion," auditing the output
        of a specialist tool against the original user request to ensure
        relevance and quality. This enables self-correction.
        """
        def __init__(self, settings: Settings):
            super().__init__(settings)
            self.api_url = settings.OLLAMA_API_URL
            self.model_name = settings.LLM_MODEL_NAME

        async def run(self, original_request: str, last_step: Dict[str, Any]) -> Dict[str, Any]:
            print("üïµÔ∏è AuditorAgent: Verifying the last tool output...")

            # Safely serialize tool output to a string for the prompt
            try:
                tool_output_str = json.dumps(last_step['tool_output'], ensure_ascii=False, indent=2)
            except Exception:
                tool_output_str = str(last_step['tool_output'])

            prompt = f"""
            You are a meticulous fact-checker and auditor. Given the user's original request and the output from a specialist tool, please audit the output for quality and relevance.

            **User's Original Request:**
            "{original_request}"

            **Tool Called:**
            {last_step['tool_name']}

            **Tool's Output:**
            ---
            {tool_output_str}
            ---

            **Audit Checklist:**
            1.  **Relevance:** Is this output directly relevant and helpful for answering the user's request?
            2.  **Accuracy:** Does the output appear factually consistent and logical?

            Based on this, provide a confidence score from 1 (not relevant/correct) to 5 (highly relevant/correct) and brief reasoning.
            Respond ONLY with a valid JSON object that conforms to this schema:
            {{
                "confidence_score": <1-5>,
                "reasoning": "Your brief reasoning here."
            }}
            """
            payload = {"model": self.model_name, "prompt": prompt, "format": "json", "stream": False}

            try:
                response = requests.post(self.api_url, json=payload).json().get("response", "{}")
                result_dict = json.loads(response)
                verification = VerificationResult(**result_dict)
                print(f"   - Audit Confidence Score: {verification.confidence_score}/5")
                return verification.dict()
            except Exception as e:
                print(f"   ‚ùå ERROR in AuditorAgent: {e}")
                return {"confidence_score": 1, "reasoning": "Error during verification."}

    ```

#### **Task 2.2.4: Create the `StrategistAgent` (for Synthesis)**

* **Rationale:** This is the final and most advanced cognitive step. After the plan is complete and all information has been gathered, a basic agent would simply list the facts. The Strategist goes further. It synthesizes the information into a single, coherent answer and attempts to **connect the dots**, generating novel insights or hypotheses based on the combined data. This is the primary value-add of the entire reasoning engine.
* **Step 1: Create the Agent File**
    * Create a new directory and file: `agents/strategist/strategist_agent.py`.
* **Step 2: Add the Code**
    * The following complete code should be placed in `agents/strategist/strategist_agent.py`.

    ```python
    import json
    import requests
    from typing import Dict, Any, List

    from agents.base_agent import BaseAgent
    from config.settings import Settings

    class StrategistAgent(BaseAgent):
        """
        This agent acts as the final synthesizer. It takes all the verified
        information from the tool execution steps and constructs a comprehensive
        final response, aiming to generate novel insights by connecting disparate facts.
        """
        def __init__(self, settings: Settings):
            super().__init__(settings)
            self.api_url = settings.OLLAMA_API_URL
            self.model_name = settings.LLM_MODEL_NAME

        async def run(self, original_request: str, intermediate_steps: List[Dict[str, Any]]) -> Dict[str, Any]:
            print("‚úçÔ∏è StrategistAgent: Synthesizing the final answer...")

            # Build a formatted context string from all the tool outputs
            context = "\\n\\n---\\n\\n".join([
                f"Step: Calling tool `{step['tool_name']}` with input `{step['tool_input']}`\\n"
                f"Observed Output:\\n{json.dumps(step['tool_output'], indent=2, ensure_ascii=False)}"
                for step in intermediate_steps
            ])

            prompt = f"""
            You are an expert financial analyst acting as a strategist. Your task is to synthesize a comprehensive, final answer to the user's request based on the context provided by your specialist agents.

            **User's Original Request:**
            {original_request}

            **Context from Specialist Agents:**
            ---
            {context}
            ---

            **Instructions:**
            1.  Carefully review the context from all tool outputs.
            2.  Construct a clear, well-written, and accurate final answer to the user's original request.
            3.  **Connect the Dots (Causal Inference):** Do not just list the facts. Your primary goal is to analyze the combined information to find connections. Is there a plausible link or correlation between different pieces of data (e.g., a client objection and a sales performance trend)?
            4.  **Frame as a Hypothesis:** If you find such a connection, clearly state it as a data-grounded hypothesis, using phrases like 'The data suggests a possible link...' or 'One potential hypothesis is...'. This is your key value-add.

            Final Answer:
            """
            payload = {"model": self.model_name, "prompt": prompt, "stream": False}

            try:
                final_answer = requests.post(self.api_url, json=payload).json().get("response", "Could not generate a final answer.")
                print("   - Generated final answer with causal inference.")
                return {"final_response": final_answer}
            except Exception as e:
                print(f"   ‚ùå ERROR in StrategistAgent: {e}")
                return {"final_response": "An error occurred during final synthesis."}
    ```

---

### Epic 2.3: Building the Cognitive Workflow

**Objective:** To completely re-architect the `orchestrator/graph.py` file. We will transform it from a linear pipeline into an advanced, cyclical graph that enables dynamic planning, execution, and self-correction. This new structure is the "reasoning engine" itself.

#### **Task 2.3.1: Re-Architect the Orchestrator Graph**

* **Rationale:** This is the culmination of Sprint 2. We are wiring together all the new cognitive agents (`Gatekeeper`, `Planner`, `Auditor`, `Strategist`) with a new `ToolExecutor` node and a conditional `Router`. This architecture allows the system to think, plan, act, and verify in a loop, rather than just processing data in a straight line.
* **File to Modify:** `orchestrator/graph.py`
* **Step 1: Add the Code**
    * The following complete code should replace the existing content of `orchestrator/graph.py`. This is a complete overhaul and represents the new heart of the Stellar Sales System.

    ```python
    from langgraph.graph import StateGraph, END
    from typing import Dict, Any

    from orchestrator.state import AgentState
    from config.settings import settings

    # --- Import ALL agents, including our new cognitive suite ---
    from agents.gatekeeper.gatekeeper_agent import GatekeeperAgent
    from agents.planner.planner_agent import PlannerAgent
    from agents.auditor.auditor_agent import AuditorAgent
    from agents.strategist.strategist_agent import StrategistAgent
    # --- Import specialist agents that will act as "tools" ---
    from agents.sales_copilot.sales_copilot_agent import SalesCopilotAgent
    # ... other specialist agents like CrmAgent, EmailAgent will be added here as tools

    # --- Initialize ALL agents ---
    gatekeeper_agent = GatekeeperAgent(settings)
    planner_agent = PlannerAgent(settings)
    auditor_agent = AuditorAgent(settings)
    strategist_agent = StrategistAgent(settings)
    sales_copilot_agent = SalesCopilotAgent(settings) # This is now a "tool"

    # --- Define the "Tools" available to the Planner ---
    # The planner will choose which of these tools to call.
    # This map makes it easy for our Tool Executor to find and run the correct agent.
    tool_map = {
        "sales_copilot_tool": sales_copilot_agent,
        # "crm_tool": CrmAgent(settings), # Example of another tool
    }

    # --- Define the Cognitive Nodes for the Graph ---

    async def gatekeeper_node(state: AgentState) -> Dict[str, Any]:
        """First node: Checks for ambiguity in the user's request."""
        result = await gatekeeper_agent.run(request=state["original_request"])
        return {"clarification_question": result["clarification_question"]}

    async def planner_node(state: AgentState) -> Dict[str, Any]:
        """Generates the step-by-step plan."""
        result = await planner_agent.run(request=state["original_request"])
        return {"plan": result["plan"]}

    async def tool_executor_node(state: AgentState) -> Dict[str, Any]:
        """Executes the next tool in the plan."""
        print("üõ†Ô∏è ToolExecutorNode: Executing the next step...")
        next_step = state["plan"][0]
        tool_name = next_step.split('(')[0]
        tool_input = eval(next_step[len(tool_name)+1:-1])

        tool_agent = tool_map[tool_name]
        result = await tool_agent.run(query=tool_input)

        new_intermediate_step = {
            "tool_name": tool_name,
            "tool_input": tool_input,
            "tool_output": result
        }
        return {
            "intermediate_steps": state.get("intermediate_steps", []) + [new_intermediate_step],
            "plan": state["plan"][1:]
        }

    async def auditor_node(state: AgentState) -> Dict[str, Any]:
        """Verifies the output of the last tool.""
        last_step = state["intermediate_steps"][-1]
        result = await auditor_agent.run(original_request=state["original_request"], last_step=last_step)
        return {"verification_history": state.get("verification_history", []) + [result]}

    async def strategist_node(state: AgentState) -> Dict[str, Any]:
        """Synthesizes the final response."""
        result = await strategist_agent.run(
            original_request=state["original_request"],
            intermediate_steps=state["intermediate_steps"]
        )
        return {"final_response": result["final_response"]}

    # --- Define the Conditional Router ---

    def router_node(state: AgentState) -> str:
        """The central decision-maker for the cognitive loop."""
        print("üö¶ RouterNode: Deciding next step...")

        if state.get("clarification_question"):
            print("   - Decision: Ambiguity detected. Halting.")
            return END

        # Check the auditor's last verification
        if state.get("verification_history"):
            last_verification = state["verification_history"][-1]
            if last_verification["confidence_score"] < 3:
                print("   - Decision: Verification failed. Returning to planner.")
                # Clear the failed plan to force replanning
                state['plan'] = []
                return "planner"

        if not state.get("plan") or state["plan"][0] == "FINISH":
            print("   - Decision: Plan is complete. Routing to strategist.")
            return "strategist"
        else:
            print("   - Decision: Plan has more steps. Routing to tool executor.")
            return "tool_executor"

    # --- Construct the Graph ---

    def create_reasoning_workflow():
        workflow = StateGraph(AgentState)

        # Add all cognitive nodes
        workflow.add_node("gatekeeper", gatekeeper_node)
        workflow.add_node("planner", planner_node)
        workflow.add_node("tool_executor", tool_executor_node)
        workflow.add_node("auditor", auditor_node)
        workflow.add_node("strategist", strategist_node)

        # Define the workflow's entry point
        workflow.set_entry_point("gatekeeper")

        # Define the edges
        workflow.add_edge("gatekeeper", "planner")
        workflow.add_edge("planner", "tool_executor")
        workflow.add_edge("tool_executor", "auditor")
        workflow.add_edge("strategist", END)

        # The conditional router is the key to the cognitive loop
        workflow.add_conditional_edges(
            "auditor",
            router_node,
            {
                "planner": "planner", # Loop back to re-plan on failure
                "tool_executor": "tool_executor", # Continue plan on success
                "strategist": "strategist", # Finish when plan is done
                END: END # Halt if ambiguity was found earlier
            }
        )

        return workflow.compile()

    # The final, compiled application graph
    app = create_reasoning_workflow()
    ```

---